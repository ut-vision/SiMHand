## ShapeNet

#### train ShapeNet

ShapeNet is a model that uses fully connected neural network to estimate shape parameters.  It's faster than pso. Code of ShapeNet are adapted from [bihand](https://github.com/lixiny/bihand). If you want train your ShapeNet, just run these. 

```python
# create training set
python create_data.py
# train the model
python train_shape_net.py
```
   As for the pre-trained model or the training set generated by me, you can download from [google drive](https://drive.google.com/drive/folders/1OEM8Q8SIJjXkembz3wlp6UiXFfpzAsLu?usp=sharing) or [bhpan](https://bhpan.buaa.edu.cn:443/link/88CD866C9EB3F30906D57571678FFE6D). Put the data_bone.npy and data_shape.npy in ROOT_DIR/data. Put the ckp_siknet_synth_41.pth.tar in ROOT_DIR/checkpoints.

```
ROOT_DIR
...
|--data
   |--data_bone.npy
   |--data_shape.npy
...
|--checkpoints
   |--ckp_siknet_synth_41.pth.tar
...
```



#### training set

   The training set is generated by MANO. More details see create_data.py.

1. First sample shape parameters from normal distribution N(0,3)

2. Calculate the relative bone length corresponding to the shape parameter.

#### loss

   The loss of ShapeNet consists of two parts, one is the error of relative bone length, the other is the regularization loss of shape parameters.

$$
L = \lambda_1 ||\hat{x} - x||_2^2 + \lambda_2 || \hat{y}||_2^2 \\
$$

​         $x$  is the input relative bone length.
​         $\hat{y}$  is the output shape parameters of ShapeNet.
​         $\hat{x}$ is  the relative bone length corresponding to the shape parameter.

​      In my opinion, shape parameters include not only relative bone length information, but also absolute bone length information. It is impossible to          guarantee that a relative bone length only corresponds to one shape parameter, which is necessary for neural networks. Therefore, the loss function does not directly calculate the error between the shape parameter and the label of it.

#### AUC

AUC of ShapeNet can refer [README.md](./README.md). You can get higher AUC, if you change " beta = torch.tanh(beta) " which is the line 85 of model/shape_net.py to  "beta = 3*torch.tanh(beta) ". This will make the output range of ShapeNet bigger and get higher AUC. According to the experiment, the finger will be thinner.

I didn't adjust the parameters carefully. Maybe you can get better results if you adjust parameters.

